
% approximate-inference.tex

\documentclass[dvipdfmx,notheorems,t]{beamer}

\usepackage{docmute}
\input{settings}

\begin{document}

\section{近似推論法}

\subsection{EMアルゴリズムが困難な場合}

\begin{frame}{EMアルゴリズムが困難な場合}

\begin{itemize}
	\item EMアルゴリズムで行う計算
	\begin{itemize}
		\item \alert{Eステップ}では、潜在変数の事後確率分布$p(\bm{Z} | \bm{X}, \bm{\theta}^\mathrm{old})$を計算
		\newline
		\item \alert{Mステップ}では、完全データ対数尤度$\ln p(\bm{X}, \bm{Z} | \bm{\theta})$の期待値を計算
		\begin{eqnarray}
			&& \mathcal{Q}(\bm{\theta}, \bm{\theta}^\mathrm{old}) = \sum_{\bm{Z}} p(\bm{Z} | \bm{X}, \bm{\theta}^\mathrm{old}) \ln p(\bm{X}, \bm{Z} | \bm{\theta}) \\
			&& \mathcal{Q}(\bm{\theta}, \bm{\theta}^\mathrm{old}) = \int_{\bm{Z}} p(\bm{Z} | \bm{X}, \bm{\theta}^\mathrm{old}) \ln p(\bm{X}, \bm{Z} | \bm{\theta}) d\bm{Z}
		\end{eqnarray}
		そして、$\mathcal{Q}(\bm{\theta}, \bm{\theta}^\mathrm{old})$を最大化するパラメータ$\bm{\theta}^\mathrm{new}$を求める
		\begin{equation}
			\bm{\theta}^\mathrm{new} = \argmax_{\bm{\theta}} \mathcal{Q}(\bm{\theta}, \bm{\theta}^\mathrm{old})
		\end{equation}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{EMアルゴリズムが困難な場合}

\begin{itemize}
	\item EMアルゴリズムの困難さ
	\begin{itemize}
		\item 実際に扱うモデルでは、事後分布$p(\bm{Z} | \bm{X}, \bm{\theta}^\mathrm{old})$の計算や、事後分布に従った期待値$\mathcal{Q}(\bm{\theta}, \bm{\theta}^\mathrm{old})$の計算が、\alert{不可能であることが多い}
		\newline
		\item 隠れ変数の\alert{次元が高すぎる}
		\item 事後分布が\alert{複雑な形をしていて}、期待値を解析的に計算できない
		\newline
		\item \alert{連続変数}であれば、積分が閉形式の解を持たないかもしれない
		\item 空間の次元の問題や、被積分項の複雑さから、数値積分すら困難かもしれない
		\newline
		\item \alert{離散変数}であれば、期待値を計算するためには、\alert{潜在変数の可能な全ての組み合わせについての和を取る}必要がある
		\item 隠れ変数の次元が高くなると、組み合わせ数が指数的に増大する
		\item 計算量が大きすぎて、期待値の厳密な計算がもはや不可能
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{EMアルゴリズムが困難な場合}

\begin{itemize}
	\item 近似法
	\begin{itemize}
		\item EMアルゴリズムが困難であるとき、何らかの方法で\alert{近似}しなければならない
		\item 近似法は、\alert{確率的な近似}と、\alert{決定的な近似}の2つに分けられる
	\end{itemize} \
	
	\item 確率的な近似
	\begin{itemize}
		\item \alert{マルコフ連鎖モンテカルロ法}などの手法がある
		\item \alert{無限の計算資源があれば}、厳密な結果が得られる
		\item 実際には計算量が有限であるため、得られる解は近似解となる
	\end{itemize} \
	
	\item 決定的な近似
	\begin{itemize}
		\item 事後分布$p(\bm{Z} | \bm{X}, \bm{\theta})$を\alert{解析的に近似}する
		\item 事後分布に対して、\alert{何らかの仮定をおく}
		\item 例えば、\alert{単純な項の積として分解できる}、あるいは、(ガウス分布などの特別な)\alert{パラメトリックな分布である}といった仮定
	\end{itemize}
\end{itemize}

\end{frame}

\subsection{変分法}

\begin{frame}{変分推論}

\begin{itemize}
	\item ここで扱う近似法
	\begin{itemize}
		\item \alert{変分推論法}(Variational inference)あるいは\alert{変分ベイズ法}(Variational Bayes)について扱う
	\end{itemize} \
	
	\item \alert{変分推論}(Variational inference)
	\begin{itemize}
		\item 18世紀のオイラー、ラグランジュらによる\alert{変分法}(Calculus of variations)に起源をもつ
		\newline
		\item まずは、変分法について説明をしていく
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 関数と\alert{汎関数}の違い
	\begin{itemize}
		\item 通常の関数は、入力として値をとり、出力として関数の値を返す
		\item 通常の関数は、\alert{値から値への写像}である
		\newline
		\item 関数の導関数は、入力値を微小に変えたときに、出力の関数値がどの程度変わるかを表す
		\newline
		\item \alert{汎関数}(Functional)とは、入力として\alert{関数をとり}、出力として汎関数の\alert{値}を返す
		\item 汎関数は、\alert{関数から値への写像}である
		\newline
		\item \alert{汎関数微分}(Functional derivative)とは、\alert{入力関数が微小に変わったとき}に、出力の汎関数値がどの程度変わるかを表す
		\newline
		\item 汎関数の微分を、\alert{変分}という
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 汎関数の例
	\begin{itemize}
		\item エントロピー$H[p]$は、確率分布$p(x)$を入力として、以下の量を返す汎関数
		\begin{equation}
			H[p] = -\int p(x) \ln p(x) dx
		\end{equation}
	\end{itemize} \
	
	\item 汎関数の最適化
	\begin{itemize}
		\item 多くの問題は、\alert{汎関数の値を最適化する問題}として定式化できる
		\newline
		\item 汎関数の最適化とは、\alert{可能な全ての入力関数の中から}、汎関数の値を最大化、あるいは最小化するような\alert{関数を選び出す}ことである
		\newline
		\item 通常の最適化では、可能な全てのパラメータ(入力値)の中から、関数を最大化、あるいは最小化するような1つのパラメータを選び出す
		\newline
		\item 次は、いよいよ\alert{変分}の計算について説明する
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 変分法
	\begin{itemize}
		\item 通常の微分を使えば、ある関数$y(x)$を最大化(最小化)するような$x$の値が求められる
		\newline
		\item \alert{変分法}を使えば、汎関数$F[y]$を最大化(最小化)するような、関数$y(x)$が求められる
		\item 従って、可能な全ての関数$y(x)$の中から、$F[y]$を最大(最小)にするような関数が得られる
	\end{itemize} \
	
	\item 変分法によって解ける問題の例
	\begin{itemize}
		\item 2点を結ぶ最短経路は? (答えは直線)
		\item 最速降下曲線は? (答えはサイクロイド)
		\item \alert{エントロピーが最大}になるような確率分布は? (答えは\alert{ガウス分布})
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 通常の微分の表現
	\begin{itemize}
		\item 関数$y(x + \epsilon)$のテイラー展開は次のように記述できた
		\begin{eqnarray}
			y(x + \epsilon) &=& \sum_{n = 0}^\infty \frac{y^{(n)}(x)}{n!} \epsilon^n \\
			&=& y(x) + \frac{dy}{dx} \epsilon + \frac{1}{2!} \frac{d^2 y}{dx^2} \epsilon^2 + \frac{1}{3!} \frac{d^3 y}{dx^3} \epsilon^3 + \cdots \\
			&=& y(x) + \frac{dy}{dx} \epsilon + O(\epsilon^2)
		\end{eqnarray}
		
		\item これより微分$dy / dx$は、次のように求められる
		\item 変数$x$に微小な変化$\epsilon$を加え、このときの関数値$y(x + \epsilon)$を$\epsilon$の累乗形として表現する
		\item 最後に$\epsilon \to 0$の極限をとればよい
		\begin{equation}
			\frac{dy}{dx} = \lim_{\epsilon \to 0} \frac{y(x + \epsilon) - y(x)}{\epsilon}
		\end{equation}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}	
	\item 多変数関数$y(x_1, \ldots, x_D)$の偏微分の表現
	\begin{itemize}
		\item 多変数関数$y(x_1, \ldots, x_D)$のテイラー展開は次のように記述できた
		\begin{equation}
			\bm{D}^n = \left( \epsilon_1 \frac{\partial y}{\partial x_i} + \cdots + \epsilon_D \frac{\partial y}{\partial x_D} \right)^n
		\end{equation}
		上記のような演算子$\bm{D}$を考えれば
		\begin{eqnarray}
			&& y(x_1 + \epsilon_1, \ldots, x_D + \epsilon_D) \nonumber \\
			&=& \sum_{n = 0}^\infty \frac{1}{n!} (\bm{D}^n y)(x_1, \ldots, x_D) \\
			&=& y(x_1, \ldots, x_D) + \sum_{i = 1}^D \frac{\partial y}{\partial x_i} \epsilon_i + \frac{1}{2!} \sum_{i = 1}^D \sum_{j = 1}^D \frac{\partial^2 y}{\partial x_i x_j} \epsilon_i \epsilon_j + \nonumber \\
			&& \qquad \frac{1}{3!} \sum_{i = 1}^D \sum_{j = 1}^D \sum_{k = 1}^D \frac{\partial^3 y}{\partial x_i x_j x_k} \epsilon_i \epsilon_j \epsilon_k + \cdots
		\end{eqnarray}
		であるから
		\begin{eqnarray}
			&& y(x_1 + \epsilon_1, \ldots, x_D + \epsilon_D) \nonumber \\
			&=& y(x_1, \ldots, x_D) + \sum_{i = 1}^D \frac{\partial y}{\partial x_i} \epsilon_i + O(\epsilon^2)
		\end{eqnarray}
		
		\item これより偏微分$\partial y/\partial x_i$は、次のように求められる
		\begin{eqnarray}
			&& \frac{\partial y}{\partial x_i} = \lim_{\epsilon_i \to 0} \frac{1}{\epsilon_i} \left( y(x_1, \ldots, x_{i - 1}, x_i + \epsilon_i, x_{i + 1}, \ldots, x_D) - \right. \nonumber \\
			&& \qquad \left. y(x_1, \ldots, x_{i - 1}, x_i, x_{i + 1}, \ldots, x_D) \right)
		\end{eqnarray}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 変分の表現
	\begin{itemize}
		\item 多少不正確だが、変分をどのように定義すればよいか考えてみる
		\newline
		\item ここで、各$x_i$に対する関数の値$z_i = y(x_i)$を個別の変数とみなして、次の関数$F(z_1, \ldots, z_D)$について考えてみよう
		\begin{eqnarray}
			&& F(z_1 + \epsilon \eta(x_1), \ldots, z_D + \epsilon \eta(x_D)) \nonumber \\
			&=& F(z_1, \ldots, z_D) + \sum_{i = 1}^D \frac{\partial F}{\partial z_i} \epsilon \eta(x_i) + O(\epsilon^2)
		\end{eqnarray}
		$z_i = y(x_i)$を代入してみると
		\begin{eqnarray}
			&& F(y(x_1) + \epsilon \eta(x_1), \ldots, y(x_D) + \epsilon \eta(x_D)) \nonumber \\
			&=& F(y(x_1), \ldots, y(x_D)) + \sum_{i = 1}^D \frac{\partial F}{\partial y(x_i)} \epsilon \eta(x_i) + O(\epsilon^2)
		\end{eqnarray}
		
		\item ここで$D \to \infty$の極限を取り、$x_1, \ldots, x_D$が、ある連続した区間$[a, b]$に含まれる、全ての実数を表すことにする
		\newline
		\item このとき$y(x_1), \ldots, y(x_D)$は、実数の区間$[a, b]$で定義される\alert{連続関数}$y(x)$として書けることが分かる
		\newline
		\item 同様に$y(x_1) + \epsilon \eta(x_1), \ldots, y(x_D) + \epsilon \eta(x_D)$は、実数の区間$[a, b]$で定義される\alert{連続関数}$y(x) + \epsilon \eta(x)$として、まとめることができる
		\newline
		\item 関数$\eta(x)$も、実数の区間$[a, b]$で定義される連続関数
		\item $\epsilon \eta(x)$は、$y(x)$に加わる\alert{摂動}として、考えることができる
		\newline
		\item 関数$F$は、関数$y(x)$や$y(x) + \epsilon \eta(x)$を入力として受け取る、\alert{汎関数}$F[y]$として解釈できるから、次のように書ける
		\begin{eqnarray}
			&& F(y(x_1) + \epsilon \eta(x_1), \ldots, y(x_D) + \epsilon \eta(x_D)) = \nonumber \\
			&& \qquad F[y(x) + \epsilon \eta(x)] \\
			&& F(y(x_1), \ldots, y(x_D)) = F[y(x)]
		\end{eqnarray}
		
		\item 以下の項は、入力を$y(x)$に摂動を加えて$y(x) + \epsilon \eta(x)$へと微小に変化させたときの、汎関数の($F[y(x)]$から$F[y(x) + \epsilon \eta(x)]$への)変化量を表している
		\begin{equation}
			\sum_{i = 1}^D \frac{\partial F}{\partial y(x_i)} \epsilon \eta(x_i)
		\end{equation}
		
		\item 点$x_i$における汎関数$F$の変化量を、$x_1, \ldots, x_D$の範囲について、即ち、実数の区間$[a, b]$について足し合わせていると解釈する
		\newline
		\item $D \to \infty$のとき、$x_1, \ldots, x_D$は区間$[a, b]$における全ての実数を表すから、総和を積分に置き換えられそうである
		\newline
		\item \color{red}汎関数の微分$\displaystyle \frac{\delta F}{\delta y(x)}$\normalcolor を使えば、次のように書ける
		\begin{eqnarray}
			&& \sum_{i = 1}^D \frac{\partial F}{\partial y(x_i)} \epsilon \eta(x_i) \nonumber \\
			&\Rightarrow& \int_a^b \frac{\delta F}{\delta y(x)} \epsilon \eta(x) dx = \epsilon \int_a^b \frac{\delta F}{\delta y(x)} \eta(x) dx
		\end{eqnarray}
		
		\item 結局、変分$\displaystyle \frac{\delta F}{\delta y(x)}$は次のように定義できる
		\begin{equation}
			\color{red}F[y(x) + \epsilon \eta(x)] = F[y(x)] + \epsilon \int_a^b \frac{\delta F}{\delta y(x)} \eta(x) dx + O(\epsilon^2)\normalcolor
		\end{equation}
		\item $F[y]$は、区間$[a, b]$で定義される関数$y$を受け取るとする
		\newline
		\item 変分$\delta F/\delta y$は、入力関数$y(x)$に、任意の微小な変化$\epsilon \eta(x)$を加えたときの、\color{red}汎関数$F[y]$の変化量\normalcolor として定義できる
		\item $\eta(x)$は$x$についての任意の関数
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{figure}[h]
	\centering
	\includegraphics[clip,scale=0.75,trim=2cm 16.5cm 1cm 2cm,page=724]{../pattern-recognition-and-machine-learning.pdf}
	\caption{$y(x)$と$y(x) + \epsilon \eta(x)$の表現}
\end{figure}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 変分法の例
	\begin{itemize}
		\item 次の図\ref{fig:function-derivative-example}を使って、実際に変分を求めてみよう
		\newline
		\item 汎関数$F[y]$は、次のように定義されるとする
		\begin{equation}
			F[y] = \int_a^b y(x) dx
		\end{equation}
		
		\item 汎関数の値$F[y(x)], F[y(x) + \epsilon \eta(x)]$は次のようになる
		\begin{eqnarray}
			&& F[y(x)] = \int_a^b y(x) dx \\
			&& F[y(x) + \epsilon \eta(x)] = \int_a^b \left( y(x) + \epsilon \eta(x) \right) dx
		\end{eqnarray}
		
		\item $F[y(x) + \epsilon \eta(x)]$は次のように分解できる
		\begin{eqnarray}
			F[y(x) + \epsilon \eta(x)] &=& \int_a^b y(x) dx + \epsilon \int_a^b \eta(x) dx \\
			&=& F[y(x)] + \epsilon \int_a^b \eta(x) dx
		\end{eqnarray}
		
		\item ここで、変分の定義式は
		\begin{equation}
			F[y(x) + \epsilon \eta(x)] = F[y(x)] + \epsilon \int_a^b \frac{\delta F}{\delta y(x)} \eta(x) dx + O(\epsilon^2)
		\end{equation}
		であったので、上の2つの式を見比べれば、変分$\delta F/\delta y$は結局
		\begin{equation}
			\frac{\delta F}{\delta y(x)} = 1
		\end{equation}
		となることが分かる
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.28]{functional-derivative.pdf}
	\caption{区間$[a, b]$で定義された関数$y(x)$の表現}
	\label{fig:function-derivative-example}
\end{figure}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 汎関数の最適化
	\begin{itemize}
		\item 汎関数$F[y]$が最大(最小)となるとき、\color{red}関数$y(x)$の微小な変化に対して、汎関数は変化しないはず\normalcolor
		\item 即ち、汎関数が最大(最小)となるとき、$F[y(x) + \epsilon \eta(x)] = F[y(x)]$が成り立つ
		\item 従って、変分の定義式から、以下が成り立つ
		\begin{equation}
			\int_a^b \frac{\delta F}{\delta y(x)} \eta(x) dx = 0
		\end{equation}
		
		\item 上式は任意の$\eta(x)$について成立しなければならない
		\item 従って、変分$\delta F/\delta y$は、任意の$x$について$0$とならなければならない
		\newline
		\item 汎関数$F[y]$が最大(最小)となるとき、\color{red}$\delta F/\delta y = 0$\normalcolor が成立することが分かった (\alert{通常の微分と同じ})
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 変分法の例
	\begin{itemize}
		\item 様々な汎関数について、変分を導出してみよう
		\item また、その汎関数が最大(最小)となるときに成り立つ条件を、導出してみよう
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}
	
\begin{itemize}
	\item 汎関数の例(1)
	\begin{itemize}
		\item $y(x)$とその微分$y'(x) = dy/dx$、そして$x$によって決まる関数\color{red}$G(y(x), y'(x), x)$\normalcolor があるとする
		\newline
		\item 汎関数$F[y]$を、$G(y(x), y'(x), x)$を区間$[a, b]$にわたって積分した結果を出力する関数として、次のように定める
		\begin{equation}
			F[y] = \int_a^b G(y(x), y'(x), x) dx
		\end{equation}
		
		\item 積分区間は無限であってもよいとする($a = -\infty, b = \infty$でもよい)
		\newline
		\item $y(x)$に摂動$\epsilon \eta(x)$を加えたときの、汎関数の値$F[y(x) + \epsilon \eta(x)]$を使って、変分$\delta F/\delta y$を調べてみる
		\begin{equation}
			F[y(x) + \epsilon \eta(x)] = \int_a^b G(y(x) + \epsilon \eta(x), y'(x) + \epsilon \eta'(x), x) dx
		\end{equation}
		ここで、被積分項のテーラー展開を考えれば
		\begin{eqnarray}
			&& G(y(x) + \epsilon \eta(x), y'(x) + \epsilon \eta'(x), x) \nonumber \\
			&=& G(y(x), y'(x), x) + \frac{\partial G}{\partial y} \epsilon \eta(x) + \nonumber \\
			&& \qquad \frac{\partial G}{\partial y'} \epsilon \eta'(x) + \frac{\partial G}{\partial x} \cdot 0 + O(\epsilon^2) \\
			&=& G(y(x), y'(x), x) + \epsilon \left( \frac{\partial G}{\partial y} \eta(x) + \frac{\partial G}{\partial y'} \eta'(x) \right) + O(\epsilon^2)
		\end{eqnarray}
		であるから
		\begin{eqnarray}
			&& F[y(x) + \epsilon \eta(x)] \nonumber \\
			&=& \int_a^b G(y(x) + \epsilon \eta(x), y'(x) + \epsilon \eta'(x), x) dx \nonumber \\
			&=& \int_a^b \bigg( G(y(x), y'(x), x) + \nonumber \\
			&& \qquad \left. \epsilon \left( \frac{\partial G}{\partial y} \eta(x) + \frac{\partial G}{\partial y'} \eta'(x) \right) + O(\epsilon^2) \right) dx \\
			&=& \int_a^b G(y(x), y'(x), x) dx + \nonumber \\
			&& \qquad \epsilon \int_a^b \left( \frac{\partial G}{\partial y} \eta(x) + \frac{\partial G}{\partial y'} \eta'(x) \right) dx + O(\epsilon^2) \\
			&=& F[y(x)] + \epsilon \int_a^b \left( \frac{\partial G}{\partial y} \eta(x) + \frac{\partial G}{\partial y'} \eta'(x) \right) dx + O(\epsilon^2)
		\end{eqnarray}
		ここで
		\begin{eqnarray}
			&& \int_a^b \left( \frac{\partial G}{\partial y} \eta(x) + \frac{\partial G}{\partial y'} \eta'(x) \right) dx \nonumber \\
			&=& \int_a^b \left( \frac{\partial G}{\partial y} \eta(x) \right) dx + \int_a^b \left( \frac{\partial G}{\partial y'} \eta'(x) \right) dx \\
			&=& \int_a^b \left( \frac{\partial G}{\partial y} \eta(x) \right) dx + \nonumber \\
			&& \qquad \left[ \frac{\partial G}{\partial y'} \eta(x) \right]_a^b - \int_a^b \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) \eta(x) dx \\
			&=& \left[ \frac{\partial G}{\partial y'} \eta(x) \right]_a^b + \int_a^b \left( \frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) \right) \eta(x) dx
		\end{eqnarray}
		である
		\newline
		\item 途中の式変形では、部分積分を使っていることに注意
		\newline
		\item いま、積分区間の両端において、$y(x)$の値は固定されているとする
		\item これを\alert{固定端条件}という (図\ref{fig:function-derivative-example-2})
		\newline
		\item このとき、$\eta(a) = \eta(b) = 0$であるから、上式の最初の項が消えて
		\begin{eqnarray}
			&& \int_a^b \left( \frac{\partial G}{\partial y} \eta(x) + \frac{\partial G}{\partial y'} \eta'(x) \right) dx \nonumber \\
			&=& \left[ \frac{\partial G}{\partial y'} \eta(x) \right]_a^b + \int_a^b \left( \frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) \right) \eta(x) dx \\
			&=& \int_a^b \left( \frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) \right) \eta(x) dx
		\end{eqnarray}
		のようになる
		
		\item 従って、摂動を加えたときの汎関数の値$F[y(x) + \epsilon \eta(x)]$は
		\begin{eqnarray}
			&& F[y(x) + \epsilon \eta(x)] \nonumber \\
			&=& F[y(x)] + \epsilon \int_a^b \left( \frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) \right) \eta(x) dx + O(\epsilon^2)
		\end{eqnarray}
		となる
		\newline
		
		\item 上式を、変分の定義式と比べれば
		\begin{equation}
			F[y(x) + \epsilon \eta(x)] = F[y(x)] + \epsilon \int_a^b \frac{\delta F}{\delta y(x)} \eta(x) dx + O(\epsilon^2)
		\end{equation}
		変分$\delta F/\delta y$は次のように書ける
		\begin{equation}
			\color{red}\frac{\delta F}{\delta y(x)} = \frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right)\normalcolor
		\end{equation}
		
		\item 汎関数$F[y]$が最大(最小)になるとき、変分$\delta F/\delta y$が$0$になる
		\item 従って、汎関数が最大(最小)になるとき、以下の方程式が成り立つ
		\begin{equation}
			\frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) = 0
		\end{equation}
		
		\item これを\alert{オイラー-ラグランジュ方程式}という
		\newline
		
		\item オイラー-ラグランジュ方程式は、次のような考え方で導出することもできる
		\newline
		\item $F[y]$が最大(最小)であれば、摂動$\epsilon \eta(x)$によって$y(x)$が少し変化しても、$F[y]$の値は変化しないはず
		\item 従って、$F[y]$が最大(最小)であるとき、\color{red}$F[y]$の$\epsilon$による微分は$0$になるはず\normalcolor
		
		\item これを数式で表現すると、次のようになる
		\begin{equation}
			\left. \frac{\partial F[y]}{\partial \epsilon} \right|_{\epsilon = 0} = 0
		\end{equation}
		左辺は通常の偏微分であり、これを計算すると
		\begin{eqnarray}
			&& \frac{\partial F[y]}{\partial \epsilon} \nonumber \\
			&=& \frac{\partial}{\partial \epsilon} \int_a^b G(y, y', x) dx \\
			&=& \int_a^b \frac{\partial}{\partial \epsilon} G(y, y', x) dx \\
			&=& \int_a^b \left( \frac{\partial G}{\partial y} \frac{\partial y}{\partial \epsilon} + \frac{\partial G}{\partial y'} \frac{\partial y'}{\partial \epsilon} + \frac{\partial G}{\partial x} \frac{\partial x}{\partial \epsilon} \right) dx \\
			&=& \int_a^b \left( \frac{\partial G}{\partial y} \eta(x) + \frac{\partial G}{\partial y'} \eta'(x) \right) dx \\
			&=& \left[ \frac{\partial G}{\partial y'} \eta(x) \right]_a^b + \int_a^b \left( \frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) \right) \eta(x) dx \\
			&& \qquad (\because \eta(a) = \eta(b) = 0) \nonumber \\
			&=& \int_a^b \left( \frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) \right) \eta(x) dx \\
			&=& 0 \nonumber
		\end{eqnarray}
		
		\item 上の式変形では、$y = y(x) + \epsilon \eta(x)$であるから
		\begin{eqnarray}
			&& \frac{\partial y}{\partial \epsilon} = \eta(x) \\
			&& \frac{\partial y'}{\partial \epsilon} = \frac{\partial}{\partial \epsilon} \left( \frac{\partial y}{\partial x} \right) = \frac{\partial}{\partial \epsilon} \left( y'(x) + \epsilon \eta'(x) \right) = \eta'(x) \\
			&& \frac{\partial x}{\partial \epsilon} = 0
		\end{eqnarray}
		が成立することを利用している
		\newline
		
		\item 任意の$\eta(x)$について、上式が恒等的に成り立つためには
		\begin{equation}
			\frac{\partial G}{\partial y} - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) = 0
		\end{equation}
		でなければならないことが分かり、先程と同様に、オイラー-ラグランジュ方程式を得る
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.28]{functional-derivative-2.pdf}
	\caption{制約条件を含んでいる場合の表現}
	\label{fig:function-derivative-example-2}
\end{figure}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 汎関数の例(2)
	\begin{itemize}
		\item 上では$G(y(x), y'(x), x)$について考えて、変分を導出した
		\item $y(x)$と$x$のみによって決まり、$y'(x)$には依存しない関数\color{red}$G(y(x), x)$\normalcolor を考えよう
		\newline
		\item 汎関数$F[y]$は、先程と同様に以下で表されるとする
		\begin{equation}
			F[y] = \int_a^b G(y(x), x) dx
		\end{equation}
		
		\item このとき変分$\delta F/\delta y$を求めるのは、非常に簡単である
		\item 先程の式に、$\partial G/\partial y' = 0$を代入すれば直ちに得られる
		\begin{equation}
			\color{red}\frac{\delta F}{\delta y(x)} = \frac{\partial G}{\partial y}\normalcolor
		\end{equation}
		
		\item あるいは以下のように書ける
		\begin{equation}
			\color{red}\frac{\delta}{\delta y(x)} \int_a^b G(y(x), x) dx = \frac{\partial}{\partial y} G(y(x), x)\normalcolor
		\end{equation}
		
		\item $F[y]$が最大(最小)であるとき、以下のオイラー-ラグランジュ方程式が成り立つ
		\begin{equation}
			\frac{\partial G}{\partial y} = 0
		\end{equation}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 汎関数の例(3)
	\begin{itemize}
		\item 今度は、$y'(x)$と$x$のみによって決まり、$y(x)$には依存しない関数\color{red}$G(y'(x), x)$\normalcolor を考えよう
		\newline
		\item この場合も変分$\delta F/\delta y$を求めるのは簡単である
		\item $G(y(x), y'(x), x)$の変分の式に、$\partial G/\partial y = 0$を代入すればよい
		\begin{equation}
			\color{red}\frac{\delta F}{\delta y(x)} = - \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right)
		\end{equation}
		
		\item オイラー-ラグランジュ方程式は次のようになる
		\begin{equation}
			- \frac{d}{dx} \left( \frac{\partial G}{\partial y'} \right) = 0
		\end{equation}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法}

\begin{itemize}
	\item 汎関数の例(4)
	\begin{itemize}
		\item $y(x)$と$y'(x)$によって決まる関数\color{red}$G(y(x), y'(x))$\normalcolor を考えよう
		\item このときのオイラー-ラグランジュ方程式を導出してみよう
		\newline
		\item $G(y(x), y'(x))$を$x$で微分すれば
		\begin{eqnarray}
			&& \frac{d}{dx} G(y, y') \nonumber \\
			&=& \frac{\partial}{\partial y} G(y, y') \frac{dy}{dx} + \frac{\partial}{\partial y'} G(y, y') \frac{dy'}{dx} \\
			&=& y' \frac{\partial}{\partial y} G(y, y') + \frac{\partial}{\partial y'} G(y, y') \frac{dy'}{dx}
		\end{eqnarray}
		となるから
		\begin{equation}
			y' \frac{\partial}{\partial y} G(y, y') = \frac{d}{dx} G(y, y') - \frac{\partial}{\partial y'} G(y, y') \frac{dy'}{dx}
		\end{equation}
		また、オイラー-ラグランジュ方程式の両辺に$y'$を掛けたものは
		\begin{equation}
			y' \frac{\partial}{\partial y} G(y, y') - y' \frac{d}{dx} \left( \frac{\partial}{\partial y'} G(y, y') \right) = 0
		\end{equation}
		これらを連立させて
		\begin{eqnarray}
			&& y' \frac{d}{dx} \left( \frac{\partial}{\partial y'} G(y, y') \right) = \frac{d}{dx} G(y, y') - \frac{\partial}{\partial y'} G(y, y') \frac{dy'}{dx} \\
			&& y' \frac{d}{dx} \left( \frac{\partial}{\partial y'} G(y, y') \right) + \frac{\partial}{\partial y'} G(y, y') \frac{dy'}{dx} = \frac{d}{dx} G(y, y') \\
			&& \frac{d}{dx} \left( y' \cdot \frac{\partial}{\partial y'} G(y, y') \right) = \frac{d}{dx} G(y, y') \\
			&& \int \left( \frac{d}{dx} \left( y' \cdot \frac{\partial}{\partial y'} G(y, y') \right) \right) dx = \nonumber \\
			&& \qquad \int \left( \frac{d}{dx} G(y, y') \right) dx + C \\
			&& G(y, y') = y' \cdot \frac{\partial}{\partial y'} G(y, y') + C
		\end{eqnarray}
		となるので、結局オイラー-ラグランジュ方程式は
		\begin{equation}
			G - y' \frac{\partial G}{\partial y'} = \mathrm{Const.}
		\end{equation}
		と書ける
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法で解ける問題の例}

\begin{itemize}
	\item 変分法で解ける問題の例(1)
	\begin{itemize}
		\item 2点$P(0, 0)$、$Q(a, b)$を結ぶ最短経路は?
		\newline
		\item 2点を結ぶ経路$y = f(x)$($0 \le x \le a$)の長さ$l$は、次のようになる
		\begin{equation}
			l = \int_0^a \sqrt{1 + \left( \frac{dy}{dx} \right)^2} dx = \int_0^a \sqrt{1 + y'^2} dx
		\end{equation}
		
		\item 被積分項が$y'$のみの関数となっていることが分かる
		\item $G(y'(x), x)$の場合の公式を使えば、$l$の$y = f(x)$による変分が求まる
		\begin{eqnarray}
			\frac{\delta l}{\delta f(x)} &=& - \frac{d}{dx} \left( \frac{\partial}{\partial y'} \sqrt{1 + y'^2} \right) \\
			&=& - \frac{d}{dx} \left( \frac{1}{2} \frac{1}{\sqrt{1 + y'^2}} \frac{\partial}{\partial y'} \left( 1 + y'^2 \right) \right) \\
			&=& - \frac{d}{dx} \frac{y'}{\sqrt{1 + y'^2}}
		\end{eqnarray}
		
		\item $l$を最小化するような$y = f(x)$は、上式の変分を$0$と等置すれば
		\begin{eqnarray}
			&& - \frac{d}{dx} \frac{y'}{\sqrt{1 + y'^2}} = 0 \\
			&\therefore& \frac{y'}{\sqrt{1 + y'^2}} = \mathrm{Const.}
		\end{eqnarray}
		
		\item これは、\color{red}$y'$が定数である\normalcolor ことを意味している
		\item 従って、\color{red}$y = C_0 x + C_1$\normalcolor と書ける
		\newline
		\item 以上より、\color{red}2点間を結ぶ最短経路は直線\normalcolor である
		\newline
		\item $y = f(x)$の形について、\alert{具体的な仮定は特に置いていない}ことに注意
		\item 変分法では、\alert{関数そのものを最適化する}
		\item 従って、関数の具体的な形については、特に仮定する必要がない
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法のまとめ}

\begin{itemize}
	\item 変分のまとめ
	\begin{itemize}
		\item これまでの計算で、次の変分が明らかとなった
		\begin{eqnarray}
			&& \frac{\delta}{\delta y(x)} \int G(y(x), y'(x), x) dx = \nonumber \\
			&& \qquad \frac{\partial}{\partial y} G(y(x), y'(x), x) - \frac{d}{dx} \left( \frac{\partial}{\partial y'} G(y(x), y'(x), x) \right) \\
			&& \frac{\delta}{\delta y(x)} \int G(y(x), x) dx = \frac{\partial}{\partial y} G(y(x), x) \\
			&& \frac{\delta}{\delta y(x)} \int G(y'(x), x) dx = - \frac{d}{dx} \left( \frac{\partial}{\partial y'} G(y'(x), x) \right)
		\end{eqnarray}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分法のまとめ}

\begin{itemize}
	\item ここまでの話の流れ
	\begin{enumerate}
		\item 変分の定義や、変分の計算法について調査した
		\newline
		\item \alert{変分}(汎関数の微分)とは、入力関数が微小に変化したときの、出力値の変化量として定義される
		\newline
		\item 汎関数が特定の形で表せるとき、変分がどのようになるか計算した
		\item 汎関数が最大(最小)になるとき、\alert{オイラー-ラグランジュ方程式}が成立した
		\newline
		\item 変分法を用いて、2点間を結ぶ最短経路が\alert{直線}になることを確認した
	\end{enumerate} \
	
	\item これからの話の流れ
	\begin{itemize}
		\item 変分最適化を、どのように推論問題に適用するのかについて調べていく
	\end{itemize}
\end{itemize}

\end{frame}

\subsection{変分推論}

\begin{frame}{変分推論}

\begin{itemize}
	\item 変分推論が必要だった理由
	\begin{itemize}
		\item 潜在変数に関する事後分布$p(\bm{Z} | \bm{X}, \bm{\theta})$の計算は、困難であることが多い
		\item $p(\bm{Z} | \bm{X}, \bm{\theta})$の厳密な計算は諦める代わりに、\alert{別の確率分布で近似}したい
		\newline
		\item 別の確率分布で近似するとき、単純な項の積として表現できるといった、\alert{何らかの仮定を置く}
	\end{itemize} \
	
	\item 変分推論の目的
	\begin{itemize}
		\item 同時分布$p(\bm{X}, \bm{Z})$が求まっているときに、\alert{事後分布}$p(\bm{Z} | \bm{X})$と、\alert{エビデンス}$p(\bm{X})$の近似を求める
	\end{itemize} \
	
	\item 注意点
	\begin{itemize}
		\item 観測変数と潜在変数をまとめて、$\bm{X}, \bm{Z}$とおく
		\item $p(\bm{X})$は、確率モデルからデータ$\bm{X}$が生起する確率である
		\item \alert{データからみたモデルの好み}と解釈できるから、$p(\bm{X})$を\alert{モデルエビデンス}という
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item 周辺分布の対数$\ln p(\bm{X})$の分解
	\begin{itemize}
		\item EMアルゴリズムのときと同様であり、次のように分解できる
		\begin{equation}
			\ln p(\bm{X}) = \mathcal{L}(q) + \KL (q || p)
		\end{equation}
		
		\item 但し、$\mathcal{L}(q)$と$\KL (q || p)$は次のように定義した
		\begin{eqnarray}
			\mathcal{L}(q) &=& \int q(\bm{Z}) \ln \frac{p(\bm{X}, \bm{Z})}{q(\bm{Z})} \\
			\KL (q || p) &=& -\int q(\bm{Z}) \ln \frac{p(\bm{Z} | \bm{X})}{q(\bm{Z})}
		\end{eqnarray}
	\end{itemize} \
		
	\item パラメータ$\bm{\theta}$の扱い
	\begin{itemize}
		\item EMアルゴリズムとは異なり、\color{red}パラメータ$\bm{\theta}$がどこにも現れていない\normalcolor
		% \item ここでは、全てのパラメータに事前分布が与えられた、\alert{完全にベイズ的なモデル}を考えている
		% \item パラメータも、確率変数として$\bm{Z}$の中に含まれている
		\item \alert{パラメータも潜在変数として扱っている}ので、パラメータベクトルは明示的には書かない
		\item ここでは、パラメータ$\bm{\theta}$については、あまり気にしない
		\newline
		\item ここでは連続潜在変数について考えるが、離散潜在変数であれば、積分を$\bm{Z}$に関する総和に置き換えればよい
	\end{itemize} \
	
	\item 下界$\mathcal{L}(q)$を最適化する動機
	\begin{itemize}
		\item $\mathcal{L}(q)$はエビデンスの対数$\ln p(\bm{X})$の下界であるから、\alert{エビデンス下界}ともいう
		\newline
		
		\item $\mathcal{L}(q)$を$q$について最大化し、従って$\KL (q || p)$を最小化できれば、分布$q(\bm{Z})$を真の事後分布$p(\bm{Z} | \bm{X})$に近づけられる
		\item $q(\bm{Z}) = p(\bm{Z} | \bm{X})$が分かれば、データ$\bm{X}$から、\color{red}潜在変数やパラメータ$\bm{Z}$が得られる\normalcolor
	\end{itemize} \
	
	\framebreak
	
	\item 下界$\mathcal{L}(q)$の最適化
	\begin{itemize}
		\item EMアルゴリズムのときと同じように、下界$\mathcal{L}(q)$を、分布$q(\bm{Z})$について最大化する
		\item これは、KLダイバージェンス$\KL (q || p)$を最小化することと等価である
		\newline
		\item 従って、\color{red}もし$q(\bm{Z})$を任意の分布にしてよければ\normalcolor 、$q(\bm{Z}) = p(\bm{Z} | \bm{X})$とおいて、KLダイバージェンスを$0$にすればよい
		\newline
		\item しかしここでは、\color{red}真の事後分布$p(\bm{Z} | \bm{X})$を求めることは不可能\normalcolor と仮定する
	\end{itemize} \
	
	\item 分布$q(\bm{Z})$の近似
	\begin{itemize}
		\item $q(\bm{Z})$の形をある程度\alert{制限する}
		\item 制限したクラスの$q(\bm{Z})$の中で、KLダイバージェンス$\KL (q || p)$を最小化するものを探す
	\end{itemize} \
	
	\item 変分推論の目的
	\begin{itemize}
		\item 分布のクラスを制限することで、$q(\bm{Z})$を計算可能にすること
		\item 表現力が豊かなクラスを使うことで、真の事後分布$p(\bm{Z} | \bm{X})$を良く近似する
		\newline
		\item 計算可能な分布のクラスの中で、\alert{可能な限り豊かな表現力を持つ}ものを選びたい
		\item 表現力が豊かな分布を使うことは、真の事後分布を、精度良く近似することにつながるのであって、従って\alert{過学習は発生しない}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item 分布$q(\bm{Z})$のクラスを制限する方法
	\begin{itemize}
		\item 例えば分布$q(\bm{Z})$を、\alert{パラメトリックな分布に限定}することができる
		\item 即ち、パラメータベクトル$\bm{\omega}$によって$q(\bm{Z} | \bm{\omega})$と記述されるような、分布に制限する
		\newline
		\item 分布$q(\bm{Z})$を、ガウス分布などの、何らかの特別なパラメトリックな分布と仮定することに相当
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item クラスを制限する別の方法(\alert{平均場近似})
	\begin{itemize}
		\item 分布$q(\bm{Z})$のクラスを制限する別の方法として、\alert{平均場近似}がある
		\newline
		\item 潜在変数$\bm{Z}$を、$M$個の\color{red}互いに排反なグループ$\left\{ \bm{Z}_1, \ldots, \bm{Z}_M \right\}$に分割\normalcolor
		\item 分布$q(\bm{Z})$が、\alert{これらのグループによって分解されると仮定}
		\begin{equation}
			q(\bm{Z}) = \prod_{i = 1}^M q_i(\bm{Z}_i)
		\end{equation}
		
		\item 分布$q$について、\alert{これ以上の仮定はしない}
		\item 従って、各因子$q_i(\bm{Z}_i)$の関数形については、\alert{何の制限も課さない}
		\newline
		\item 平均場近似とは、元々は物理学における用語である
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item 下界$\mathcal{L}(q)$の最大化
	\begin{itemize}
		\item $q(\bm{Z}) = \prod_i q_i(\bm{Z}_i)$と分解できるような分布$q(\bm{Z})$の中で、\color{red}下界$\mathcal{L}(q)$を最大にするもの\normalcolor を探す
		\newline
		\item $\mathcal{L}(q)$を$q(\bm{Z})$について最大化するために、$\mathcal{L}(q)$を各因子$q_i(\bm{Z}_i)$について\color{red}順番に最大化\normalcolor していく
		\item $\mathcal{L}(q)$に$q(\bm{Z}) = \prod_i q_i(\bm{Z}_i)$を代入して、因子の一つ$q_j(\bm{Z}_j)$に関する\alert{依存項}を抜き出してみよう
		\begin{eqnarray}
			\mathcal{L}(q) &=& \int q(\bm{Z}) \ln \frac{p(\bm{X}, \bm{Z})}{q(\bm{Z})} d\bm{Z} \\
			&=& \int \left( \prod_i q_i(\bm{Z}_i) \right) \ln \frac{p(\bm{X}, \bm{Z})}{q(\bm{Z})} d\bm{Z} \\
			&=& \int \prod_i q_i(\bm{Z}_i) \left( \ln p(\bm{X}, \bm{Z}) - \sum_i \ln q_i(\bm{Z}_i) \right) d\bm{Z} \\
			&=& \int \prod_i q_i(\bm{Z}_i) \left( \ln p(\bm{X}, \bm{Z}) \right) d\bm{Z} - \nonumber \\
			&& \qquad \int \prod_i q_i(\bm{Z}_i) \left( \sum_i \ln q_i(\bm{Z}_i) \right) d\bm{Z}
		\end{eqnarray}
		ここで第1項は
		\begin{eqnarray}
			&& \int \prod_i q_i(\bm{Z}_i) \left( \ln p(\bm{X}, \bm{Z}) \right) d\bm{Z} \nonumber \\
			&=& \int q_j(\bm{Z}_j) \left( \prod_{i \neq j} q_i(\bm{Z}_i) \right) \left( \ln p(\bm{X}, \bm{Z}) \right) d\bm{Z}
		\end{eqnarray}
		$d\bm{Z} = d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M$であるから
		\begin{eqnarray}
			&=& \int q_j(\bm{Z}_j) \left( \prod_{i \neq j} q_i(\bm{Z}_i) \right) \left( \ln p(\bm{X}, \bm{Z}) \right) d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M \\
			&=& \int q_j(\bm{Z}_j) \left( \ln p(\bm{X}, \bm{Z}) \right) \left( \prod_{i \neq j} q_i(\bm{Z}_i) \right) \left( \prod_{i \neq j} d\bm{Z}_i \right) d\bm{Z}_j \\
			&=& \int q_j(\bm{Z}_j) \left( \int \left( \ln p(\bm{X}, \bm{Z}) \right) \prod_{i \neq j} q_i(\bm{Z}_i) d\bm{Z}_i \right) d\bm{Z}_j \\
			&=& \int q_j(\bm{Z}_j) \ln \widetilde{p}(\bm{X}, \bm{Z}_j) d\bm{Z}_j
		\end{eqnarray}
		
		\item 但し、新しい分布$\widetilde{p}(\bm{X}, \bm{Z}_j)$は以下の式で定義した(積分の結果であるため、定数項が出現する)
		\begin{equation}
			\ln \widetilde{p}(\bm{X}, \bm{Z}_j) = \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] + \mathrm{Const.}
		\end{equation}
		
		\item 記法$\mathbb{E}_{i \neq j}$は、$i \neq j$をみたす全ての分布$q_i(\bm{Z}_i)$による、期待値を取ることを表す
		\begin{equation}
			\mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] = \int \left( \ln p(\bm{X}, \bm{Z}) \right) \prod_{i \neq j} q_i(\bm{Z}_i) d\bm{Z}_i
		\end{equation}
		
		\item 第2項は
		\begin{eqnarray}
			&& \int \prod_i q_i(\bm{Z}_i) \left( \sum_i \ln q_i(\bm{Z}_i) \right) d\bm{Z} \nonumber \\
			&=& \sum_i \int \prod_i q_i(\bm{Z}_i) \left( \ln q_i(\bm{Z}_i) \right) d\bm{Z} \\
			&=& \sum_i \int \prod_k q_k(\bm{Z}_k) \left( \ln q_i(\bm{Z}_i) \right) d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M \\
			&=& \int \prod_k q_k(\bm{Z}_k) \left( \ln q_j(\bm{Z}_j) \right) d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M + \nonumber \\
			&& \qquad \sum_{i \neq j} \int \prod_k q_k(\bm{Z}_k) \left( \ln q_i(\bm{Z}_i) \right) d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M
		\end{eqnarray}
		但し
		\begin{eqnarray}
			&& \int \prod_k q_k(\bm{Z}_k) \left( \ln q_j(\bm{Z}_j) \right) d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M \\
			&=& \int q_j(\bm{Z}_j) \ln q_j(\bm{Z}_j) \left( \prod_{k \neq j} q_k(\bm{Z}_k) \right) \left( \prod_{k \neq j} d\bm{Z}_k \right) d\bm{Z}_j \\
			&=& \int q_j(\bm{Z}_j) \ln q_j(\bm{Z}_j) \left( \int \prod_{k \neq j} q_k(\bm{Z}_k) d\bm{Z}_k \right) d\bm{Z}_j \\
			&=& \int q_j(\bm{Z}_j) \ln q_j(\bm{Z}_j) \prod_{k \neq j} \underbrace{\left( \int q_k(\bm{Z}_k) d\bm{Z}_k \right)}_{=1} d\bm{Z}_j \\
			&=& \int q_j(\bm{Z}_j) \ln q_j(\bm{Z}_j) d\bm{Z}_j
		\end{eqnarray}
		であるほか
		\begin{eqnarray}
			&& \sum_{i \neq j} \int \prod_k q_k(\bm{Z}_k) \left( \ln q_i(\bm{Z}_i) \right) d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M \nonumber \\
			&=& \sum_{i \neq j} \int q_i(\bm{Z}_i) q_j(\bm{Z}_j) \left( \prod_{k \neq i, j} \ln q_k(\bm{Z}_k) \right) \nonumber \\
			&& \qquad \left( \ln q_i(\bm{Z}_i) \right) \left( \prod_{k \neq i, j} d\bm{Z}_k \right) d\bm{Z}_i d\bm{Z}_j \\
			&=& \sum_{i \neq j} \underbrace{\left( \int q_j(\bm{Z}_j) d\bm{Z}_j \right)}_{=1} \left( \int \prod_{k \neq i, j} \ln q_k(\bm{Z}_k) d\bm{Z}_k \right) \nonumber \\
			&& \qquad \int \ln q_i(\bm{Z}_i) q_i(\bm{Z}_i) d\bm{Z}_i \\
			&=& \sum_{i \neq j} \prod_{k \neq i, j} \underbrace{\left( \int \ln q_k(\bm{Z}_k) d\bm{Z}_k \right)}_{=\mathrm{Const.}} \underbrace{\int \ln q_i(\bm{Z}_i) q_i(\bm{Z}_i) d\bm{Z}_i}_{=\mathrm{Const.}} \\
			&=& \sum_{i \neq j} \mathrm{Const.} = \mathrm{Const.}
		\end{eqnarray}
		となるから結局
		\begin{eqnarray}
			&& \int \prod_i q_i(\bm{Z}_i) \left( \sum_i \ln q_i(\bm{Z}_i) \right) d\bm{Z} \nonumber \\
			&=& \int q_j(\bm{Z}_j) \ln q_j(\bm{Z}_j) d\bm{Z}_j + \mathrm{Const.}
		\end{eqnarray}
		
		\item 従って、下界$\mathcal{L}(q)$から$q_j(\bm{Z}_j)$に依存する項を取り出すと
		\begin{eqnarray}
			&& \mathcal{L}(q) = \int q_j(\bm{Z}_j) \ln \widetilde{p}(\bm{X}, \bm{Z}_j) d\bm{Z}_j - \nonumber \\
			&& \qquad \int q_j(\bm{Z}_j) \ln q_j(\bm{Z}_j) d\bm{Z}_j + \mathrm{Const.}
		\end{eqnarray}
		但し
		\begin{equation}
			\ln \widetilde{p}(\bm{X}, \bm{Z}_j) = \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] = \int \ln p(\bm{X}, \bm{Z}) \prod_{i \neq j} q_i(\bm{Z}_i) d\bm{Z}_i
		\end{equation}
		
		\item $\mathcal{L}(q)$を、$i \neq j$である全ての$q_i(\bm{Z}_i)$について固定した上で、$q_j(\bm{Z}_j)$について最大化する
		\item $q_j(\bm{Z}_j)$について可能な全ての分布の中で、$\mathcal{L}(q)$を最大にするようなものを選ぶ
		
		\item $\mathcal{L}(q)$は次のように変形できる
		\begin{eqnarray}
			\mathcal{L}(q) &=& \int q_j(\bm{Z}_j) \ln \frac{\widetilde{p}(\bm{X}, \bm{Z}_j)}{q_j(\bm{Z}_j)} d\bm{Z}_j + \mathrm{Const.} \\
			&=& - \KL \left( q_j(\bm{Z}_j) || \widetilde{p}(\bm{X}, \bm{Z}_j) \right) + \mathrm{Const.}
		\end{eqnarray}
		
		\item これより、$\mathcal{L}(q)$は$q_j(\bm{Z}_j)$と$\widetilde{p}(\bm{X}, \bm{Z}_j)$の間の、負のKLダイバージェンスとなっている
		\item そして、$\mathcal{L}(q)$の$q_j(\bm{Z}_j)$に関する最大化は、\alert{KLダイバージェンスの最小化}と等価
		\newline
		\item KLダイバージェンスを最小にするためには、$q_j(\bm{Z}_j) = \widetilde{p}(\bm{X}, \bm{Z}_j)$とすればよい
		\newline
		\item 従って、$q_j(\bm{Z}_j)$の最適解は、次のように書ける
		\begin{equation}
			\color{red}\ln q_j^*(\bm{Z}_j) = \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] + \mathrm{Const.}\normalcolor
		\end{equation}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item 下界$\mathcal{L}(q)$を最大化する$\ln q_j(\bm{Z}_j)$の解
	\begin{itemize}
		\item $q_j(\bm{Z}_j)$の最適解は次のように書けた
		\begin{equation}
			\ln q_j^*(\bm{Z}_j) = \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] + \mathrm{Const.}
		\end{equation}
		
		\item 上式は次のことを意味している
		\item 因子$q_j(\bm{Z}_j)$の最適解の対数$\ln q_j^*(\bm{Z}_j)$は、観測データ$\bm{X}$と潜在変数$\bm{Z}$の\alert{同時分布の対数}$\ln p(\bm{X}, \bm{Z})$\alert{を考え}、$i \neq j$である他の因子$q_i(\bm{Z}_i)$について\alert{期待値を取ったもの}である
		\newline
		
		\item 定数項は、正規化することで得られるので、結局次のようになる
		\begin{equation}
			q_j^*(\bm{Z}_j) = \frac{\exp(\mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})])}{\displaystyle \int \exp(\mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})]) d\bm{Z}_j}
		\end{equation}
		
		\item 正規化定数は必要に応じて計算すればよいので、取り敢えず無視できる
		\newline
		
		\item 最適解の式は、$q(\bm{Z})$の分解の数だけ得られるので、$\left\{ q_i(\bm{Z}_i) \right\}$に関する$M$本の連立方程式となる
		\item この方程式は、分布$q(\bm{Z})$が$M$個の因子に分解されるという仮定の下で、下界$\mathcal{L}(q)$の最大値が満たすべき条件である
		\newline
		
		\item $\ln q_j^*(\bm{Z}_j)$の右辺は、$i \neq j$である$q_i(\bm{Z}_i)$の期待値に依存するため、$q_j^*(\bm{Z}_j)$を陽に求めることができない
		\item そこで、下界$\mathcal{L}(q)$は次のように最適化される(\alert{重要})
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item 下界$\mathcal{L}(q)$の最適化
	\begin{enumerate}
		\item 全ての因子$q_j(\bm{Z}_j)$を適当に初期化する
		\newline
		\item 各因子を、以下の式を使って更新する \label{enum:variational-inference-step}
		\begin{eqnarray}
			&& \ln q_j(\bm{Z}_j) = \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] + \mathrm{Const.} \\
			&& \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] = \int \ln p(\bm{X}, \bm{Z}) \prod_{i \neq j} q_i(\bm{Z}_i) d\bm{Z}_i
		\end{eqnarray}
		即ち、因子$q_j(\bm{Z}_j)$を、他の全ての因子の現在の値$q_i(\bm{Z}_i)$を使って改良する
		\newline
		\item (\ref{enum:variational-inference-step})を、下界$\mathcal{L}(q)$が収束するまで繰り返す
	\end{enumerate}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item ここまでの話の流れ
	\begin{enumerate}
		\item $\ln p(\bm{X}) = \mathcal{L}(q) + \KL (q(\bm{Z}) || p(\bm{Z} | \bm{X}))$であるから、\alert{エビデンス下界}$\mathcal{L}(q)$を\color{red}$q$について最大化\normalcolor すれば、$\KL (q || p) = 0$とでき、従って$q(\bm{Z}) = p(\bm{Z} | \bm{X})$を得る
		\newline
		\item $q(\bm{Z}) = p(\bm{Z} | \bm{X})$が分かれば、データ$\bm{X}$から、\color{red}潜在変数やパラメータ$\bm{Z}$が得られる\normalcolor (パラメータは潜在変数$\bm{Z}$に含まれている)
		\newline
		\item しかし、事後分布$q(\bm{Z}) = p(\bm{Z} | \bm{X})$は\alert{計算不可能}なので、何らかの方法で\alert{近似}するしかない
		\newline
		\item 近似するといっても、計算可能でなければならないので、$q(\bm{Z})$の形には、通常\alert{何らかの制限}を課す
		\newline
		\item $q(\bm{Z})$を、\alert{パラメトリックな分布}$q(\bm{Z} | \bm{\omega})$と仮定することがある
		\newline
		\item または、$q(\bm{Z})$を、$\prod_i q_i(\bm{Z}_i)$のように分解できるとする(\alert{平均場近似})
		\newline
		\item \alert{平均場近似}を行うとき、各因子$q_j(\bm{Z}_j)$の最適解は、$\ln q_j^*(\bm{Z}_j) = \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] + \mathrm{Const.}$であった
		\newline
		\item 全ての因子$\left\{ q_j(\bm{Z}_j) \right\}$を\alert{同時に最適化することはできない}
		\newline
		\item 下界$\mathcal{L}(q)$を、各因子$q_j(\bm{Z}_j)$について\alert{順番に最適化}することはできる
	\end{enumerate} \
	
	\item これからの話の流れ
	\begin{itemize}
		\item 分解$q(\bm{Z}) = \prod_i q_i(\bm{Z}_i)$によって$p(\bm{Z} | \bm{X})$を近似するときの、弊害を調べる
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item $q(\bm{Z})$の分解による近似の性質
	\begin{itemize}
		\item 変分推論では、真の事後分布$q(\bm{Z}) = p(\bm{Z} | \bm{X})$を、分解により近似する
		\item 分解で近似することによって、\alert{どのような不正確さが生じるのか?}
	\end{itemize} \
	
	\item ガウス分布の分解による近似
	\begin{itemize}
		\item ガウス分布を、\alert{分解されたガウス分布}で近似することを考えてみよう
		\item 分解による近似で、どのような問題が起こるのか考えてみよう
		\newline
		\item 2つの変数$\bm{z} = (z_1, z_2)$間には、\alert{相関がある}とする
		\item $\bm{z}$はガウス分布$p(\bm{z}) = \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1})$に従っているとする
		\begin{equation}
			\bm{\mu} = \left[ \begin{array}{l} \mu_1 \\ \mu_2 \end{array} \right], \qquad \bm{\Lambda} = \left[ \begin{array}{ll} \Lambda_{11} & \Lambda_{12} \\ \Lambda_{21} & \Lambda_{22} \end{array} \right]
		\end{equation}
		
		\item 精度行列$\bm{\Lambda}$は対称行列であるから、$\Lambda_{12} = \Lambda_{21}$
		\newline
		\item この分布$p(\bm{z})$を、分解されたガウス分布$q(\bm{z}) = q_1(z_1) q_2(z_2)$で近似する
		\item 各因子$q_1(z_1), q_2(z_2)$の関数形については\alert{何の仮定も置いていない}ことに注意
	\end{itemize} \
	
	\item 最適な因子$q_1(z_1), q_2(z_2)$の計算
	\begin{itemize}
		\item 最適な因子$q_1^*(z_1)$を、先程の結果を使って求める
		\begin{equation}
			\ln q_j(\bm{Z}_j) = \mathbb{E}_{i \neq j}[\ln p(\bm{X}, \bm{Z})] + \mathrm{Const.}
		\end{equation}
		
		\item 従って、$q_1^*(z_1)$を計算する式は次のようになる
		\begin{eqnarray}
			&& \ln q_1^*(z_1) = \mathbb{E}_{z_2}[\ln p(\bm{z})] + \mathrm{Const.} \\
			&& \mathbb{E}_{z_2}[\ln p(\bm{z})] = \int \ln p(\bm{z}) q_2(z_2) dz_2
		\end{eqnarray}
		
		\item 上式の右辺では、$z_1$に依存する項だけを考えればよい
		\item $z_1$の関数を求めようとしているため
		\item $z_1$に依存しない項は、全て定数項(正規化定数)に含まれてしまうため
		\newline
		\item 従って$q_1^*(z_1)$は
		\begin{eqnarray}
			\ln q_1^*(z_1) &=& \mathbb{E}_{z_2}[\ln p(\bm{z})] + \mathrm{Const.} \\
			&=& \mathbb{E}_{z_2} \left[ \ln \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1}) \right] + \mathrm{Const.}
		\end{eqnarray}
		但し
		\begin{eqnarray}
			&& \ln \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1}) \nonumber \\
			&=& \ln \left( \frac{1}{(2\pi)^\frac{2}{2}} \frac{1}{|\bm{\Lambda}^{-1}|^\frac{1}{2}} \exp \left( -\frac{1}{2} (\bm{z} - \bm{\mu})^T \left( \bm{\Lambda}^{-1} \right)^{-1} (\bm{z} - \bm{\mu}) \right) \right) \nonumber \\
			&=& \ln \left( \frac{1}{2\pi} \frac{1}{|\bm{\Lambda}|^{-\frac{1}{2}}} \exp \left( -\frac{1}{2} (\bm{z} - \bm{\mu})^T \bm{\Lambda} (\bm{z} - \bm{\mu}) \right) \right) \nonumber \\
			&=& -\frac{1}{2} (\bm{z} - \bm{\mu})^T \bm{\Lambda} (\bm{z} - \bm{\mu}) + \mathrm{Const.}
		\end{eqnarray}
		$z_1$に依存する項だけを取り出せば
		\begin{eqnarray}
			&& -\frac{1}{2} (\bm{z} - \bm{\mu})^T \bm{\Lambda} (\bm{z} - \bm{\mu}) \nonumber \\
			&=& -\frac{1}{2} \left[ z_1 - \mu_1, z_2 - \mu_2 \right] \left[ \begin{array}{ll} \Lambda_{11} & \Lambda_{12} \\ \Lambda_{21} & \Lambda_{22} \end{array} \right] \left[ \begin{array}{l} z_1 - \mu_1 \\ z_2 - \mu_2 \end{array} \right] \nonumber \\
			&=& -\frac{1}{2} \bigg[ \Big\{ (\Lambda_{11} (z_1 - \mu_1) + \Lambda_{21} (z_2 - \mu_2) \Big\} (z_1 - \mu_1) + \nonumber \\
			&& \qquad \Big\{ \Lambda_{12} (z_1 - \mu_1) + \Lambda_{22} (z_2 - \mu_2) \Big\} (z_2 - \mu_2) \bigg] \nonumber \\
			&=& -\frac{1}{2} \left( \Lambda_{11} (z_1 - \mu_1)^2 + 2 \Lambda_{12} (z_1 - \mu_1)(z_2 - \mu_2) + \right. \nonumber \\
			&& \qquad \left. \Lambda_{22} (z_2 - \mu_2)^2 \right) \quad (\because \Lambda_{21} = \Lambda_{12}) \nonumber \\
			&=& -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 - \Lambda_{12} (z_1 - \mu_1)(z_2 - \mu_2) + \mathrm{Const.}
		\end{eqnarray}
		これを代入して
		\begin{eqnarray}
			&& \ln \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1}) \nonumber \\
			&=& -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 - \Lambda_{12} (z_1 - \mu_1)(z_2 - \mu_2) + \mathrm{Const.}
		\end{eqnarray}
		従って
		\begin{eqnarray}
			&& \ln q_1^*(z_1) \nonumber \\
			&=& \mathbb{E}_{z_2} \left[ \ln \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1}) \right] + \mathrm{Const.} \nonumber \\
			&=& \mathbb{E}_{z_2} \left[ -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 - \Lambda_{12} (z_1 - \mu_1)(z_2 - \mu_2) \right] + \mathrm{Const.} \nonumber \\
			&=& -\frac{1}{2} \Lambda_{11} z_1^2 + \Lambda_{11} \mu_1 z_1 - \Lambda_{12} z_1 \left( \mathbb{E}[z_2] - \mu_2 \right) + \mathrm{Const.}
		\end{eqnarray}
		
		\item これより、$q_1^*(z_1)$は次のように書ける
		\begin{eqnarray}
			&& q_1^*(z_1) \nonumber \\
			&\propto& \exp \left( -\frac{1}{2} \Lambda_{11} z_1^2 + \Lambda_{11} \mu_1 z_1 - \Lambda_{12} z_1 \left( \mathbb{E}[z_2] - \mu_2 \right) \right) \nonumber \\
			&=& \exp \left( -\frac{1}{2} \Lambda_{11} \left( z_1 - (\mu_1 - \Lambda_{11}^{-1} \Lambda_{12} (\mathbb{E}[z_2] - \mu_2)) \right)^2 + \right. \nonumber \\
			&& \qquad \left. \frac{1}{2} \Lambda_{11} \left( \mu_1 - \Lambda_{11}^{-1} \Lambda_{12} (\mathbb{E}[z_2] - \mu_2) \right)^2 \right) \nonumber \\
			&\propto& \exp \left( -\frac{1}{2 \Lambda_{11}^{-1}} \left( z_1 - (\mu_1 - \Lambda_{11}^{-1} \Lambda_{12} (\mathbb{E}[z_2] - \mu_2)) \right)^2 \right) \nonumber \\
			&=& \mathcal{N}(z_1 | m_1, \Lambda_{11}^{-1})
		\end{eqnarray}
		但し$m_1$は次のようにおいた
		\begin{equation}
			m_1 = \mu_1 - \Lambda_{11}^{-1} \Lambda_{12} (\mathbb{E}[z_2] - \mu_2)
		\end{equation}
		
		\item 対称性から、$q_2^*(z_2)$も次のように求められる
		\begin{eqnarray}
			\ln q_2^*(z_2) &=& \mathbb{E}_{z_2}[\ln p(\bm{z})] + \mathrm{Const.} \\
			&=& \mathbb{E}_{z_2}[\ln \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1})] + \mathrm{Const.}
		\end{eqnarray}
		\begin{equation}
			q_2^*(z_2) = \mathcal{N}(z_2 | m_2, \Lambda_{22}^{-1})
		\end{equation}
		但し$m_2$は次のようにおいた
		\begin{equation}
			m_2 = \mu_2 - \Lambda_{22}^{-1} \Lambda_{21} (\mathbb{E}[z_1] - \mu_1)
		\end{equation}
		
		\item これより$q_1^*(z_1), q_2^*(z_2)$は
		\begin{eqnarray}
			q_1^*(z_1) &=& \mathcal{N}(z_1 | m_1, \Lambda_{11}^{-1}) \\
			m_1 &=& \mu_1 - \Lambda_{11}^{-1} \Lambda_{12} (\mathbb{E}[z_2] - \mu_2) \\
			q_2^*(z_2) &=& \mathcal{N}(z_2 | m_2, \Lambda_{22}^{-1}) \\
			m_2 &=& \mu_2 - \Lambda_{22}^{-1} \Lambda_{21} (\mathbb{E}[z_1] - \mu_1)
		\end{eqnarray}
	\end{itemize} \
	
	\item 注意点1
	\begin{itemize}
		\item $q_1^*(z_1)$は、$q_2^*(z_2)$を使って計算される$p(\bm{z})$の期待値$\mathbb{E}[z_2]$に依存 (逆も成り立つ)
		\item $q_1^*(z_1)$と、$q_2^*(z_2)$は\alert{相互に依存している}ため、2つを同時に求めることはできない
		\item その代わりに、次のように最適化すればよい
		\newline
		\item $q_1(z_1), q_2(z_2)$を適当に初期化したあと、$q_1^*(z_1), q_2^*(z_2)$の式を使って、交互に$q_1(z_1)$と$q_2(z_2)$を更新していく(収束するまでこれを繰り返す)
	\end{itemize} \
	
	\item 注意点2
	\begin{itemize}
		\item $q_1(z_1), q_2(z_2)$の具体的な関数形については、\alert{何の仮定も置かなかった}
		\item $q_i^*(z_i)$がガウス分布だという仮定は置いていないが、$\KL (q || p)$を最適化する\alert{変分推論}によって、\alert{結果的にガウス分布が得られた}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{変分推論}

\begin{itemize}
	\item $\KL(q || p)$の最適化と$\KL(p || q)$の最適化の比較
	\begin{itemize}
		\item 上記の結果は、$\KL(q || p)$の最適化(エビデンス下界$\mathcal{L}(q)$の最適化)によって得た
		\item $\KL(q || p)$ではなく、\color{red}$\KL(p || q)$を最適化したらどうなるか?\normalcolor
		\item 変分推論ではない、もう一つの近似推論の方法である、\alert{EP法}で使われる考え方
		\newline
		\item $q(\bm{Z})$を$p(\bm{Z} | \bm{X})$に近づけたいのであれば、$\KL(q || p)$と$\KL(p || q)$のどちらを最小化してもよいはず
		\item なぜなら、KLダイバージェンスは、確率分布間の(擬似的な)距離を表すため
	\end{itemize} \
	
	\item $\KL(p || q)$の最適化
	\begin{itemize}
		\item $q(\bm{Z})$が平均場近似によって分解できるとき、$\KL(p || q)$を最適化したい
		\newline
		\item KLダイバージェンス$\KL(p || q)$は、次のように書ける
		\begin{eqnarray}
			\KL(p || q) &\equiv& \KL(p(\bm{Z} | \bm{X}) || q(\bm{Z})) \\
			&=& -\int p(\bm{Z} | \bm{X}) \ln \frac{q(\bm{Z})}{p(\bm{Z} | \bm{X})} d\bm{Z} \\
			&=& -\int p(\bm{Z} | \bm{X}) \left( \ln q(\bm{Z}) - \ln p(\bm{Z} | \bm{X}) \right) d\bm{Z} \\
			&=& -\int p(\bm{Z} | \bm{X}) \ln q(\bm{Z}) d\bm{Z} - \nonumber \\
			&& \qquad -\underbrace{\int p(\bm{Z} | \bm{X}) \ln p(\bm{Z} | \bm{X}) d\bm{Z}}_{\text{$q$には依存しない定数項}} \\
			&=& -\int p(\bm{Z} | \bm{X}) \ln \prod_i q_i(\bm{Z}_i) d\bm{Z} + \mathrm{Const.} \\
			&=& -\int p(\bm{Z} | \bm{X}) \sum_i \ln q_i(\bm{Z}_i) d\bm{Z} + \mathrm{Const.} \\
			&=& -\sum_i \int p(\bm{Z} | \bm{X}) \ln q_i(\bm{Z}_i) d\bm{Z} + \mathrm{Const.}
		\end{eqnarray}
		定数項は、$p(\bm{Z} | \bm{X})$のエントロピーであり、$q$には依存しない
		\newline
		
		\item 各因子$q_j(\bm{Z}_j)$について$\KL(p || q)$を最適化したい
		\item このとき、$i \neq j$となる、全ての$q_i(\bm{Z}_i)$は\alert{固定する}
		\newline
		\item $q_j(\bm{Z}_j)$に依存する項を取り出せば、次のようになる
		\begin{eqnarray}
			&& \sum_i \int p(\bm{Z} | \bm{X}) \ln q_i(\bm{Z}_i) d\bm{Z} \nonumber \\
			&=& \int p(\bm{Z} | \bm{X}) \ln q_j(\bm{Z}_j) d\bm{Z} \\
			&=& \int p(\bm{Z} | \bm{X}) \ln q_j(\bm{Z}_j) d\bm{Z}_1 d\bm{Z}_2 \cdots d\bm{Z}_M \\
			&=& \int p(\bm{Z} | \bm{X}) \ln q_j(\bm{Z}_j) d\bm{Z}_j \left( \prod_{i \neq j} d\bm{Z}_i \right) \\
			&=& \int \left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right) \ln q_j(\bm{Z}_j) d\bm{Z}_j
		\end{eqnarray}
		
		\item $q_j(\bm{Z}_j)$は確率分布であるから、以下の条件を満たさなければならない
		\begin{eqnarray}
			&& \int q_j(\bm{Z}_j) d\bm{Z}_j = 1 \quad (\color{red}\text{規格化条件}\normalcolor ) \\
			&& q_j(\bm{Z}_j) \ge 0
		\end{eqnarray}
		
		\item 従って$\KL(p || q)$を$q_j(\bm{Z}_j)$について最適化するとき、\alert{ラグランジュの未定乗数法}を使って、規格化条件を組み込む必要がある
		\newline
		\item $q_j(\bm{Z}_j) \ge 0$という条件は、$\ln q_i(\bm{Z}_i)$という項が既にあるから、何もしなくても\alert{常に満たされる} (ラグランジュ関数に、制約条件を改めて取り入れる必要がない)
		\newline
		
		\item 結局、ラグランジュ汎関数$\mathcal{L}[q_j]$は、次のようになる
		\begin{eqnarray}
			\mathcal{L}[q_j] &=& - \int \left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right) \ln q_j(\bm{Z}_j) d\bm{Z}_j + \nonumber \\
			&& \lambda \left( \int q_j(\bm{Z}_j) d\bm{Z}_j - 1 \right)
		\end{eqnarray}
		
		\item 上記は$q_j(\bm{Z}_j)$についての\alert{汎関数}となっていることに注意
		\newline
		
		\item 次の公式を使って、$\mathcal{L}[q_j]$を変分最適化する
		\begin{equation}
			\frac{\delta}{\delta y(x)} \int G(y(x), x) dx = \frac{\partial}{\partial y} G(y(x), x)
		\end{equation}
		
		\item 従って
		\begin{eqnarray}
			&& \frac{\delta}{\delta q_j(\bm{Z}_j)} \mathcal{L}[q_j] \nonumber \\
			&=& - \frac{\delta}{\delta q_j(\bm{Z}_j)} \int \left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right) \ln q_j(\bm{Z}_j) d\bm{Z}_j + \nonumber \\
			&& \qquad \frac{\delta}{\delta q_j(\bm{Z}_j)} \lambda \left( \int q_j(\bm{Z}_j) d\bm{Z}_j - 1 \right) \\
			&=& - \frac{\partial}{\partial q_j} \left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right) \ln q_j(\bm{Z}_j) + \nonumber \\
			&& \qquad \lambda \frac{\partial}{\partial q_j} q_j(\bm{Z}_j) \\
			&=& - \left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right) \frac{1}{q_j(\bm{Z}_j)} + \lambda = 0
		\end{eqnarray}
		
		\item これより、未定乗数$\lambda$は
		\begin{eqnarray}
			&& \lambda q_j(\bm{Z}_j) = \left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right) \frac{1}{q_j(\bm{Z}_j)} \\
			&\Rightarrow& \int \lambda q_j(\bm{Z}_j) d\bm{Z}_j = \int \underbrace{\left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right)}_{=p(\bm{Z}_j | \bm{X})} d\bm{Z}_j \\
			&\Rightarrow& \lambda \underbrace{\int q_j(\bm{Z}_j) d\bm{Z}_j}_{=1} = \underbrace{\int p(\bm{Z}_j | \bm{X}) d\bm{Z}_j}_{=1} \\
			&\Rightarrow& \lambda = 1
		\end{eqnarray}
		
		\item 結局、最適解$q_j^*(\bm{Z}_j)$は次のようになる
		\begin{eqnarray}
			&& - \left( \int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i \right) \frac{1}{q_j(\bm{Z}_j)} + \lambda = 0 \\
			&\Rightarrow& q_j^*(\bm{Z}_j) = \underbrace{\int p(\bm{Z} | \bm{X}) \prod_{i \neq j} d\bm{Z}_i}_{=p(\bm{Z}_j | \bm{X})} \\
			&\Rightarrow& q_j^*(\bm{Z}_j) = p(\bm{Z}_j | \bm{X})
		\end{eqnarray}
		
		\item $q_j^(\bm{Z}_j)$の最適解は、$p(\bm{Z} | \bm{X})$を、$i \neq j$である全ての$\bm{Z}_i$について周辺化した分布
		\item これは閉じた解であり、繰り返しを必要としない
		\newline
		
		\item 今回の場合は$p(\bm{z} | \bm{x}) = p(\bm{z})$の場合を考えており、かつ$p(\bm{z}) = \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1})$であった
		\newline
		
		\item 従って、$q_1^*(z_1)$は
		\begin{eqnarray}
			&& q_1^*(z_1) \nonumber \\
			&=& \int p(\bm{z}) dz_2 \nonumber \\
			&=& \int \mathcal{N}(\bm{z} | \bm{\mu}, \bm{\Lambda}^{-1}) dz_2 \\
			&=& \frac{1}{2\pi} \frac{1}{|\bm{\Lambda}|^{-\frac{1}{2}}} \int \exp \left( -\frac{1}{2} (\bm{z} - \bm{\mu})^T \bm{\Lambda} (\bm{z} - \bm{\mu}) \right) dz_2
		\end{eqnarray}
		ここで
		\begin{eqnarray}
			&& -\frac{1}{2} (\bm{z} - \bm{\mu})^T \bm{\Lambda} (\bm{z} - \bm{\mu}) \nonumber \\
			&=& -\frac{1}{2} \left( \Lambda_{11} (z_1 - \mu_1)^2 + \right. \nonumber \\
			&& \qquad \left. 2 \Lambda_{12} (z_1 - \mu_1)(z_2 - \mu_2) + \Lambda_{22} (z_2 - \mu_2)^2 \right) \\
			&=& -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 + \Lambda_{12} (z_1 - \mu_1) \mu_2 + \nonumber \\
			&& \qquad -\frac{1}{2} \left( 2 \Lambda_{12} (z_1 - \mu_1) z_2 + \Lambda_{22} (z_2 - \mu_2)^2 \right)
		\end{eqnarray}
		そして
		\begin{eqnarray}
			&& -\frac{1}{2} \left( 2 \Lambda_{12} (z_1 - \mu_1) z_2 + \Lambda_{22} (z_2 - \mu_2)^2 \right) \nonumber \\
			&=& -\frac{1}{2} \left( \Lambda_{22} z_2^2 - 2 \Lambda_{22} \mu_2 z_2 + 2 \Lambda_{12} (z_1 - \mu_1) z_2 + \Lambda_{22} \mu_2^2 \right) \\
			&=& -\frac{1}{2} \left( \Lambda_{22} z_2^2 - 2 \left( \Lambda_{22} \mu_2 - \Lambda_{12} (z_1 - \mu_1) \right) z_2 + \Lambda_{22} \mu_2^2 \right) \\
			&=& -\frac{1}{2} \left( \Lambda_{22} \left( z_2 - \Lambda_{22}^{-1} \left( \Lambda_{22} \mu_2 - \Lambda_{12} (z_1 - \mu_1) \right) \right)^2 - \right. \nonumber \\
			&& \qquad \left. \Lambda_{22} \left( \Lambda_{22}^{-1} \left( \Lambda_{22} \mu_2 - \Lambda_{12} (z_1 - \mu_1) \right) \right)^2 + \Lambda_{22} \mu_2^2 \right) \\
			&=& -\frac{1}{2} \left( \Lambda_{22} \left( z_2 - \Lambda_{22}^{-1} m \right)^2 - \Lambda_{22}^{-1} m^2 + \Lambda_{22} \mu_2^2 \right)
		\end{eqnarray}
		ゆえ($m = \Lambda_{22} \mu_2 - \Lambda_{12} (z_1 - \mu_1)$とおいた)
		\begin{eqnarray}
			&& -\frac{1}{2} (\bm{z} - \bm{\mu})^T \bm{\Lambda} (\bm{z} - \bm{\mu}) \nonumber \\
			&=& -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 + \Lambda_{12} (z_1 - \mu_1) \mu_2 + \Lambda_{22} \mu_2^2 - \nonumber \\
			&& \qquad \frac{1}{2} \Lambda_{22} \left( z_2 - \Lambda_{22}^{-1} m \right)^2 + \frac{1}{2} \Lambda_{22}^{-1} m^2
		\end{eqnarray}
		これより
		\begin{eqnarray}
			&& \int \exp \left( -\frac{1}{2} (\bm{z} - \bm{\mu})^T \bm{\Lambda} (\bm{z} - \bm{\mu}) \right) dz_2 \nonumber \\
			&=& \exp \left( -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 + \Lambda_{12} (z_1 - \mu_1) \mu_2 + \right. \nonumber \\
			&& \qquad \left. \Lambda_{22} \mu_2^2 + \frac{1}{2} \Lambda_{22}^{-1} m^2 \right) \nonumber \\
			&& \qquad \int \exp \left( - \frac{1}{2} \Lambda_{22} \left( z_2 - \Lambda_{22}^{-1} m \right)^2 \right) dz_2
		\end{eqnarray}
		であって、右側の積分は、中身が(正規化されていない)ガウス分布であるから
		\begin{eqnarray}
			&& \int \exp \left( - \frac{1}{2} \Lambda_{22} \left( z_2 - \Lambda_{22}^{-1} m \right)^2 \right) dz_2 \nonumber \\
			&=& (2\pi \Lambda_{22}^{-1}) \cdot \int \frac{1}{(2\pi \Lambda_{22}^{-1})^\frac{1}{2}} \exp \left( - \frac{1}{2} \Lambda_{22} \left( z_2 - \Lambda_{22}^{-1} m \right)^2 \right) dz_2 \nonumber \\
			&=& 2\pi \Lambda_{22}^{-1}
		\end{eqnarray}
		となって、$z_2$を積分により消去できるほか、指数の残りの部分から、$z_1$に依存する項だけを取り出して
		\begin{eqnarray}
			&& -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 + \Lambda_{12} (z_1 - \mu_1) \mu_2 + \Lambda_{22} \mu_2^2 + \frac{1}{2} \Lambda_{22}^{-1} m^2 \nonumber \\
			&=& -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 + \Lambda_{12} (z_1 - \mu_1) \mu_2 + \Lambda_{22} \mu_2^2 + \nonumber \\
			&& \qquad \frac{1}{2} \Lambda_{22}^{-1} \left( \Lambda_{22} \mu_2 - \Lambda_{12} (z_1 - \mu_1) \right)^2 \nonumber \\
			&=& -\frac{1}{2} \Lambda_{11} (z_1 - \mu_1)^2 + \Lambda_{12} (z_1 - \mu_1) \mu_2 + \Lambda_{22} \mu_2^2 + \nonumber \\
			&& \qquad \frac{1}{2} \Lambda_{22} \mu_2^2 - \mu_2 \Lambda_{12} (z_1 - \mu_1) + \nonumber \\
			&& \qquad \frac{1}{2} \Lambda_{22}^{-1} \Lambda_{12}^2 (z_1 - \mu_1)^2 \\
			&=& -\frac{1}{2} \left( \Lambda_{11} - \Lambda_{22}^{-1} \Lambda_{12}^2 \right) (z_1 - \mu_1)^2 + \mathrm{Const.} \nonumber \\
			&=& -\frac{1}{2} \left( \Lambda_{11} - \Lambda_{22}^{-1} \Lambda_{12}^2 \right) (z_1 - \mu_1)^2 + \mathrm{Const.} \\
			&=& -\frac{1}{2} \left( \Lambda_{11} - \Lambda_{22}^{-1} \Lambda_{12}^2 \right) z_1^2 + \nonumber \\
			&& \qquad \frac{1}{2} \left( \Lambda_{11} - \Lambda_{22}^{-1} \Lambda_{12}^2 \right) \mu_1 z_1 + \mathrm{Const.}
		\end{eqnarray}
	\end{itemize}
\end{itemize}

\end{frame}

\end{document}
